{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jahan08/Brain-MRI-Images-Augmentation-with-DC-GAN/blob/main/Application_of_DC_GAN_in_Generating_Brain_MRI_Images.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "2Av2la0Yc3iv",
        "outputId": "78f57e25-3e73-46f8-f559-18e46fa2bc1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A Solution - Generative Modelling\n",
        "\n",
        "<p style=\"font-size:20px\">Generative models, or deep generative models, are a class of deep learning models that learn the underlying data distribution from the sample. These models can be used to reduce data into its fundamental properties, or to generate new samples of data with new and varied properties</p>\n",
        "\n",
        "# Generative Adversarial Networks\n",
        "\n",
        "<p style=\"font-size:20px\">Generative adversarial networks are implicit likelihood models that generate data samples from the statistical distribution of the data. They’re used to copy variations within the dataset. They use a combination of two networks: generator and discriminator.</p>\n",
        "<br>\n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:720/1*9jwIuW0KPi3THIvoYg9BUQ.png\" />\n",
        "\n",
        "\n",
        "\n",
        "## <u> The Generator: </u>\n",
        "<p style=\"font-size:20px\">A generator network takes a random normal distribution (z), and outputs a generated sample that’s close to the original distribution.</p>\n",
        "\n",
        "## <u> The Discriminator: </u>\n",
        "<p style=\"font-size:20px\">A discriminator tries to evaluate the output generated by the generator with the original sample, and outputs a value between 0 and 1. If the value is close to 0, then the generated sample is fake, and if the value is close to 1 then the generated sample is real.</p>\n",
        "\n",
        "## <u> What the Entire thing looks like: </u>\n",
        "\n",
        "<br><img src=\"https://s3.amazonaws.com/kajabi-storefronts-production/blogs/12746/images/iAOOdduQyCICwiv31aHa_dcgan.png\">\n",
        "\n",
        "## <u> How do GANs work ? </u>\n",
        "\n",
        "<p style=\"font-size:20px\">A random normal distribution is fed into the generator. The generator then outputs a random distribution, since it doesn’t have a reference point. <br>\n",
        "Meanwhile, an actual sample, or ground truth, is fed into the discriminator. The discriminator learns the distribution of the actual sample. When the generated sample from the generator is fed into the discriminator, it evaluates the distribution.<br>\n",
        "If the distribution of the generated sample is close to the original sample, then the discriminator outputs a value close to ‘1’ = real. If both the distribution doesn’t match or they aren’t even close to each other, then the discriminator outputs a value close to ‘0’ = fake.</p>\n",
        "\n",
        "## <u> The Minimax setting </u>\n",
        "\n",
        "<br><img src=\"https://static.packt-cdn.com/products/9781789139907/graphics/bf03e5ab-69ac-424d-84a7-48ea85e616ec.png\" style=\"width:900px; height:150px;\">\n",
        "\n",
        "<p style=\"font-size:20px\">The answer lies in the loss function or the value function; it measures the distance between the distribution of the data generated and the distribution of the real data. Both the generator and the discriminator have their own loss functions. The generator tries to minimize the loss function while the discriminator tries to maximize.</p>"
      ],
      "metadata": {
        "id": "6F4RFQ2ActVb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup\n",
        "\n",
        "**In this project, I have used**\n",
        "* Numpy and Tensorflow for Mathematical Operations\n",
        "* Matplotlib and OpenCV for Image data handling and Visualization\n",
        "* Keras for the Neural Networks"
      ],
      "metadata": {
        "id": "xQ6k9hPPctVc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "import os\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Flatten, Conv2D, Reshape, Input, Conv2DTranspose\n",
        "from keras.layers import Activation, LeakyReLU, BatchNormalization, Dropout, Resizing\n",
        "from keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.applications import VGG16\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "try:\n",
        "    from tensorflow.keras.optimizers import Adam\n",
        "except:\n",
        "    from keras.optimizers import Adam"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-29T11:44:12.594479Z",
          "iopub.execute_input": "2023-03-29T11:44:12.59486Z",
          "iopub.status.idle": "2023-03-29T11:44:12.604828Z",
          "shell.execute_reply.started": "2023-03-29T11:44:12.594819Z",
          "shell.execute_reply": "2023-03-29T11:44:12.603794Z"
        },
        "trusted": true,
        "id": "DIcGCEQ2ctVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NOISE_DIM = 100\n",
        "BATCH_SIZE = 4\n",
        "STEPS_PER_EPOCH = 3750\n",
        "EPOCHS = 10\n",
        "SEED = 40\n",
        "WIDTH, HEIGHT, CHANNELS = 128, 128, 1\n",
        "\n",
        "OPTIMIZER = Adam(0.0002, 0.5)"
      ],
      "metadata": {
        "id": "k-YEhz2NvqGm",
        "execution": {
          "iopub.status.busy": "2023-03-29T11:31:49.628577Z",
          "iopub.execute_input": "2023-03-29T11:31:49.629252Z",
          "iopub.status.idle": "2023-03-29T11:31:49.644775Z",
          "shell.execute_reply.started": "2023-03-29T11:31:49.629209Z",
          "shell.execute_reply": "2023-03-29T11:31:49.643093Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAIN_DIR = \"/content/drive/MyDrive/Brain-Cancer-MRI-Image/yes\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-29T11:31:49.646064Z",
          "iopub.execute_input": "2023-03-29T11:31:49.646497Z",
          "iopub.status.idle": "2023-03-29T11:31:49.65726Z",
          "shell.execute_reply.started": "2023-03-29T11:31:49.646463Z",
          "shell.execute_reply": "2023-03-29T11:31:49.65634Z"
        },
        "trusted": true,
        "id": "FvvNzqACctVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading and Preprocessing the Images"
      ],
      "metadata": {
        "id": "iQHnV8_3ctVd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_images(folder):\n",
        "\n",
        "    imgs = []\n",
        "    target = 1\n",
        "    labels = []\n",
        "    for i in os.listdir(folder):\n",
        "        img_dir = os.path.join(folder,i)\n",
        "        try:\n",
        "            img = cv2.imread(img_dir)\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "            img = cv2.resize(img, (128,128))\n",
        "            imgs.append(img)\n",
        "            labels.append(target)\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    imgs = np.array(imgs)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    return imgs, labels"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-29T11:31:49.660965Z",
          "iopub.execute_input": "2023-03-29T11:31:49.661263Z",
          "iopub.status.idle": "2023-03-29T11:31:49.669825Z",
          "shell.execute_reply.started": "2023-03-29T11:31:49.661238Z",
          "shell.execute_reply": "2023-03-29T11:31:49.668989Z"
        },
        "trusted": true,
        "id": "SDhEKkFkctVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data, labels = load_images(MAIN_DIR)\n",
        "data.shape, labels.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-29T11:31:49.670916Z",
          "iopub.execute_input": "2023-03-29T11:31:49.671496Z",
          "iopub.status.idle": "2023-03-29T11:31:51.402642Z",
          "shell.execute_reply.started": "2023-03-29T11:31:49.671462Z",
          "shell.execute_reply": "2023-03-29T11:31:51.401767Z"
        },
        "trusted": true,
        "id": "UR9ZeEcactVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate 20 random numbers to index images from data"
      ],
      "metadata": {
        "id": "4oLa5RxDctVe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(SEED)\n",
        "idxs = np.random.randint(0, 155, 20)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-29T11:31:51.40393Z",
          "iopub.execute_input": "2023-03-29T11:31:51.404271Z",
          "iopub.status.idle": "2023-03-29T11:31:51.411127Z",
          "shell.execute_reply.started": "2023-03-29T11:31:51.404236Z",
          "shell.execute_reply": "2023-03-29T11:31:51.410166Z"
        },
        "trusted": true,
        "id": "imPOTOTsctVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = data[idxs]\n",
        "X_train.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-29T11:31:51.413262Z",
          "iopub.execute_input": "2023-03-29T11:31:51.414038Z",
          "iopub.status.idle": "2023-03-29T11:31:51.42225Z",
          "shell.execute_reply.started": "2023-03-29T11:31:51.414002Z",
          "shell.execute_reply": "2023-03-29T11:31:51.421111Z"
        },
        "trusted": true,
        "id": "MAR6awkActVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normalize and Reshape the Data"
      ],
      "metadata": {
        "id": "EU0k2L-FctVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the Images\n",
        "X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
        "\n",
        "# Reshape images\n",
        "X_train = X_train.reshape(-1, WIDTH,HEIGHT,CHANNELS)\n",
        "\n",
        "# Check shape\n",
        "X_train.shape"
      ],
      "metadata": {
        "id": "mE3l1VfUb_jg",
        "execution": {
          "iopub.status.busy": "2023-03-29T11:31:51.424082Z",
          "iopub.execute_input": "2023-03-29T11:31:51.424461Z",
          "iopub.status.idle": "2023-03-29T11:31:51.435695Z",
          "shell.execute_reply.started": "2023-03-29T11:31:51.424429Z",
          "shell.execute_reply": "2023-03-29T11:31:51.434761Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting The Real Images"
      ],
      "metadata": {
        "id": "8JLHefLmctVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,8))\n",
        "for i in range(10):\n",
        "    axs = plt.subplot(2,5,i+1)\n",
        "    plt.imshow(X_train[i], cmap=\"gray\")\n",
        "    plt.axis('off')\n",
        "    axs.set_xticklabels([])\n",
        "    axs.set_yticklabels([])\n",
        "    plt.subplots_adjust(wspace=None, hspace=None)\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-29T11:31:51.437108Z",
          "iopub.execute_input": "2023-03-29T11:31:51.437441Z",
          "iopub.status.idle": "2023-03-29T11:31:52.417206Z",
          "shell.execute_reply.started": "2023-03-29T11:31:51.437409Z",
          "shell.execute_reply": "2023-03-29T11:31:52.41636Z"
        },
        "trusted": true,
        "id": "u-iExzKoctVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Architecture"
      ],
      "metadata": {
        "id": "B7YPm42ectVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_generator():\n",
        "\n",
        "    \"\"\"\n",
        "        Generator model \"generates\" images using random noise. The random noise AKA Latent Vector\n",
        "        is sampled from a Normal Distribution which is given as the input to the Generator. Using\n",
        "        Transposed Convolution, the latent vector is transformed to produce an image\n",
        "        We use 3 Conv2DTranspose layers (which help in producing an image using features; opposite\n",
        "        of Convolutional Learning)\n",
        "\n",
        "        Input: Random Noise / Latent Vector\n",
        "        Output: Image\n",
        "    \"\"\"\n",
        "\n",
        "    model = Sequential([\n",
        "\n",
        "        Dense(32*32*256, input_dim=NOISE_DIM),\n",
        "        LeakyReLU(alpha=0.2),\n",
        "        Reshape((32,32,256)),\n",
        "\n",
        "        Conv2DTranspose(128, (4, 4), strides=2, padding='same'),\n",
        "        LeakyReLU(alpha=0.2),\n",
        "\n",
        "        Conv2DTranspose(128, (4, 4), strides=2, padding='same'),\n",
        "        LeakyReLU(alpha=0.2),\n",
        "\n",
        "        Conv2D(CHANNELS, (4, 4), padding='same', activation='tanh')\n",
        "    ],\n",
        "    name=\"generator\")\n",
        "    model.summary()\n",
        "    model.compile(loss=\"binary_crossentropy\", optimizer=OPTIMIZER)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "hqNmekiQvutW",
        "execution": {
          "iopub.status.busy": "2023-03-29T11:31:52.420679Z",
          "iopub.execute_input": "2023-03-29T11:31:52.421275Z",
          "iopub.status.idle": "2023-03-29T11:31:52.431426Z",
          "shell.execute_reply.started": "2023-03-29T11:31:52.421239Z",
          "shell.execute_reply": "2023-03-29T11:31:52.43039Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_discriminator():\n",
        "\n",
        "    \"\"\"\n",
        "        Discriminator is the model which is responsible for classifying the generated images\n",
        "        as fake or real. Our end goal is to create a Generator so powerful that the Discriminator\n",
        "        is unable to classify real and fake images\n",
        "        A simple Convolutional Neural Network with 2 Conv2D layers connected to a Dense output layer\n",
        "        Output layer activation is Sigmoid since this is a Binary Classifier\n",
        "\n",
        "        Input: Generated / Real Image\n",
        "        Output: Validity of Image (Fake or Real)\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    model = Sequential([\n",
        "\n",
        "        Conv2D(64, (3, 3), padding='same', input_shape=(WIDTH, HEIGHT, CHANNELS)),\n",
        "        LeakyReLU(alpha=0.2),\n",
        "\n",
        "        Conv2D(128, (3, 3), strides=2, padding='same'),\n",
        "        LeakyReLU(alpha=0.2),\n",
        "\n",
        "        Conv2D(128, (3, 3), strides=2, padding='same'),\n",
        "        LeakyReLU(alpha=0.2),\n",
        "\n",
        "        Conv2D(256, (3, 3), strides=2, padding='same'),\n",
        "        LeakyReLU(alpha=0.2),\n",
        "\n",
        "        Flatten(),\n",
        "        Dropout(0.4),\n",
        "        Dense(1, activation=\"sigmoid\", input_shape=(WIDTH, HEIGHT, CHANNELS))\n",
        "    ], name=\"discriminator\")\n",
        "    model.summary()\n",
        "    model.compile(loss=\"binary_crossentropy\",\n",
        "                        optimizer=OPTIMIZER)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "xbCbfY8EvsiT",
        "execution": {
          "iopub.status.busy": "2023-03-29T11:31:52.433058Z",
          "iopub.execute_input": "2023-03-29T11:31:52.434375Z",
          "iopub.status.idle": "2023-03-29T11:31:52.445047Z",
          "shell.execute_reply.started": "2023-03-29T11:31:52.434114Z",
          "shell.execute_reply": "2023-03-29T11:31:52.443856Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Putting it together"
      ],
      "metadata": {
        "id": "KY_zfSN0ctVg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\n')\n",
        "discriminator = build_discriminator()\n",
        "print('\\n')\n",
        "generator = build_generator()\n",
        "\n",
        "discriminator.trainable = False\n",
        "\n",
        "gan_input = Input(shape=(NOISE_DIM,))\n",
        "fake_image = generator(gan_input)\n",
        "\n",
        "gan_output = discriminator(fake_image)\n",
        "\n",
        "gan = Model(gan_input, gan_output, name=\"gan_model\")\n",
        "gan.compile(loss=\"binary_crossentropy\", optimizer=OPTIMIZER)\n",
        "\n",
        "print(\"The Combined Network:\\n\")\n",
        "gan.summary()"
      ],
      "metadata": {
        "id": "6smhRLnsvuqY",
        "execution": {
          "iopub.status.busy": "2023-03-29T11:31:52.446404Z",
          "iopub.execute_input": "2023-03-29T11:31:52.447369Z",
          "iopub.status.idle": "2023-03-29T11:31:54.800722Z",
          "shell.execute_reply.started": "2023-03-29T11:31:52.447334Z",
          "shell.execute_reply": "2023-03-29T11:31:54.799766Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_images(noise, subplots, figsize=(22,8), save=False):\n",
        "    generated_images = generator.predict(noise)\n",
        "    plt.figure(figsize=figsize)\n",
        "\n",
        "    for i, image in enumerate(generated_images):\n",
        "        plt.subplot(subplots[0], subplots[1], i+1)\n",
        "        if CHANNELS == 1:\n",
        "            plt.imshow(image.reshape((WIDTH, HEIGHT)), cmap='gray')\n",
        "\n",
        "        else:\n",
        "            plt.imshow(image.reshape((WIDTH, HEIGHT, CHANNELS)))\n",
        "        if save == True:\n",
        "            img_name = \"gen\" + str(i)\n",
        "            plt.savefig(img_name)\n",
        "        plt.subplots_adjust(wspace=None, hspace=None)\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "JDm4yLl5hwFX",
        "execution": {
          "iopub.status.busy": "2023-03-29T11:31:54.802043Z",
          "iopub.execute_input": "2023-03-29T11:31:54.802886Z",
          "iopub.status.idle": "2023-03-29T11:31:54.81166Z",
          "shell.execute_reply.started": "2023-03-29T11:31:54.802849Z",
          "shell.execute_reply": "2023-03-29T11:31:54.810446Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Training"
      ],
      "metadata": {
        "id": "GNxybZbRctVg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(SEED)\n",
        "for epoch in range(10):\n",
        "    for batch in tqdm(range(STEPS_PER_EPOCH)):\n",
        "\n",
        "        noise = np.random.normal(0,1, size=(BATCH_SIZE, NOISE_DIM))\n",
        "        fake_X = generator.predict(noise)\n",
        "\n",
        "        idx = np.random.randint(0, X_train.shape[0], size=BATCH_SIZE)\n",
        "        real_X = X_train[idx]\n",
        "\n",
        "        X = np.concatenate((real_X, fake_X))\n",
        "\n",
        "        disc_y = np.zeros(2*BATCH_SIZE)\n",
        "        disc_y[:BATCH_SIZE] = 1\n",
        "\n",
        "        d_loss = discriminator.train_on_batch(X, disc_y)\n",
        "\n",
        "        y_gen = np.ones(BATCH_SIZE)\n",
        "        g_loss = gan.train_on_batch(noise, y_gen)\n",
        "\n",
        "    print(f\"EPOCH: {epoch + 1} Generator Loss: {g_loss:.4f} Discriminator Loss: {d_loss:.4f}\")\n",
        "    noise = np.random.normal(0, 1, size=(10,NOISE_DIM))\n",
        "    sample_images(noise, (2,5))"
      ],
      "metadata": {
        "id": "V6hFoFDfvunl",
        "execution": {
          "iopub.status.busy": "2023-03-29T11:32:08.137239Z",
          "iopub.execute_input": "2023-03-29T11:32:08.137609Z",
          "iopub.status.idle": "2023-03-29T11:37:35.075243Z",
          "shell.execute_reply.started": "2023-03-29T11:32:08.137577Z",
          "shell.execute_reply": "2023-03-29T11:37:35.074398Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let's generate some images !"
      ],
      "metadata": {
        "id": "EgDANjo5ctVg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "noise = np.random.normal(0, 1, size=(100, NOISE_DIM))\n",
        "sample_images(noise, (10,10), (24,20), save=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-29T11:39:36.175671Z",
          "iopub.execute_input": "2023-03-29T11:39:36.176119Z",
          "iopub.status.idle": "2023-03-29T11:40:45.58117Z",
          "shell.execute_reply.started": "2023-03-29T11:39:36.176082Z",
          "shell.execute_reply": "2023-03-29T11:40:45.576802Z"
        },
        "trusted": true,
        "id": "wEC4O8ntctVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing the Generated sample: Plotting the Distributions\n",
        "\n",
        "<p style=\"font-size:20px\">In this test, we compare the generated images with the real samples by plotting their distributions. If the distributions overlap, that indicates the generated samples are very close to the real ones\n",
        "</p>"
      ],
      "metadata": {
        "id": "5eATvf3pctVg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generated_images = generator.predict(noise)\n",
        "generated_images.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-29T11:41:09.67433Z",
          "iopub.execute_input": "2023-03-29T11:41:09.674698Z",
          "iopub.status.idle": "2023-03-29T11:41:09.818348Z",
          "shell.execute_reply.started": "2023-03-29T11:41:09.674667Z",
          "shell.execute_reply": "2023-03-29T11:41:09.814485Z"
        },
        "trusted": true,
        "id": "fqrfVzVWctVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(ncols=1, nrows=1, figsize=(18,10))\n",
        "\n",
        "sns.distplot(X_train, label='Real Images', hist=True, color='#fc0328', ax=axs)\n",
        "sns.distplot(generated_images, label='Generated Images', hist=True, color='#0c06c7', ax=axs)\n",
        "\n",
        "axs.legend(loc='upper right', prop={'size': 12})\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-03-29T11:41:11.202655Z",
          "iopub.execute_input": "2023-03-29T11:41:11.203121Z",
          "iopub.status.idle": "2023-03-29T11:41:18.561659Z",
          "shell.execute_reply.started": "2023-03-29T11:41:11.203082Z",
          "shell.execute_reply": "2023-03-29T11:41:18.560668Z"
        },
        "trusted": true,
        "id": "Yin6nXrrctVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Some other testing methods\n",
        "\n",
        "<p style=\"font-size:20px\">\n",
        "<ul>\n",
        "    <li style=\"font-size:20px\">Average Log-likelihood</li>\n",
        "    <li style=\"font-size:20px\">Inception Score</li>\n",
        "    <li style=\"font-size:20px\">Wasserstien Metric</li>\n",
        "</ul>\n",
        "</p>"
      ],
      "metadata": {
        "id": "rkzGfA30ctVh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion\n",
        "\n",
        "<p style=\"font-size:20px\">\n",
        "    As we can see from the plot, the distribution of Generated Images is approximately the same as that of the Real Images. From this we can conclude that the generated images are a true representative of the real ones, capturing most of the variations.\n",
        "</p>"
      ],
      "metadata": {
        "id": "7ddcBrW9ctVh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "\n",
        "<p style=\"font-size:20px\">\n",
        "<ul>\n",
        "    <li style=\"font-size:20px\"><a href=\"https://arxiv.org/abs/1406.2661\">Generative Adversarial Networks</a> (2014)</li>\n",
        "    <li style=\"font-size:20px\"><a href=\"https://arxiv.org/abs/1606.03498\">Improved Techniques for Training GANs</a> (2016)</li>\n",
        "    <li style=\"font-size:20px\"><a href=\"https://arxiv.org/abs/2108.03235\">SMOTified-GAN for class imbalanced pattern classification problems</a> (2021)</li>\n",
        "</ul>\n",
        "</p>"
      ],
      "metadata": {
        "id": "I3WNJGScctVh"
      }
    }
  ]
}